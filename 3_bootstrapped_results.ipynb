{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Sourcing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-27T20:24:12.339660Z",
     "start_time": "2020-11-27T20:24:11.761378Z"
    }
   },
   "outputs": [],
   "source": [
    "import pkg_resources\n",
    "import pip\n",
    "installedPackages = {pkg.key for pkg in pkg_resources.working_set}\n",
    "required = {'researchpy', 'missingno', 'folium', 'pydotplus','bokeh','imblearn', 'catboost'}\n",
    "missing = required - installedPackages\n",
    "if missing:\n",
    "    !pip install researchpy\n",
    "    !pip install missingno\n",
    "    !pip install folium\n",
    "    !pip install pydotplus\n",
    "    !pip install bokeh\n",
    "    !pip install imblearn\n",
    "    !pip install catboost\n",
    "    #!pip install xgboost\n",
    "    #!pip install graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-27T20:24:12.347928Z",
     "start_time": "2020-11-27T20:24:12.342096Z"
    }
   },
   "outputs": [],
   "source": [
    "#Disable the warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-27T20:24:15.437730Z",
     "start_time": "2020-11-27T20:24:12.351468Z"
    }
   },
   "outputs": [],
   "source": [
    "import timeit\n",
    "start_time = timeit.default_timer()  #timestamp to calculate total runtime\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import researchpy as rp\n",
    "import missingno as msno\n",
    "import itertools\n",
    "import scipy.stats as ss\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import folium\n",
    "from folium import plugins\n",
    "import graphviz\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn import feature_selection\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, accuracy_score, \\\n",
    "precision_score, recall_score, roc_auc_score, f1_score, precision_recall_curve, auc \n",
    "\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_columns', None)  # prevent column output trancation\n",
    "sns.set()  # change plot styling from Matlab's 90s feel to today's Seaborn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-27T20:24:31.163613Z",
     "start_time": "2020-11-27T20:24:15.442418Z"
    }
   },
   "outputs": [],
   "source": [
    "# File Directories\n",
    "path_crashes = 'data/crashes.sample2020.csv'\n",
    "path_vehicles = 'data/vehicles.sample.csv'\n",
    "path_people = 'data/people.sample.csv'\n",
    "\n",
    "# Import samples\n",
    "crashes = pd.read_csv(path_crashes, parse_dates=[\"CRASH_DATE\", \"CRASH_DATE_EST_I\", \"DATE_POLICE_NOTIFIED\"],\n",
    "                      low_memory=False, dtype=object)\n",
    "vehicles = pd.read_csv(path_vehicles, parse_dates=[\"CRASH_DATE\"], low_memory=False, dtype=object)\n",
    "people = pd.read_csv(path_people, parse_dates=[\"CRASH_DATE\"], low_memory=False, dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-27T20:24:32.366614Z",
     "start_time": "2020-11-27T20:24:31.165824Z"
    }
   },
   "outputs": [],
   "source": [
    "# Joining datasets\n",
    "non_passengers=people[people.PERSON_ID.str.contains('^O')]\n",
    "\n",
    "vehicles_with_people=vehicles.merge(non_passengers,how='left',on=['CRASH_RECORD_ID','RD_NO','CRASH_DATE','VEHICLE_ID'])\n",
    "\n",
    "data=crashes.merge(vehicles_with_people,how='inner',on=['CRASH_RECORD_ID','RD_NO','CRASH_DATE'])\n",
    "\n",
    "# Feature Selection\n",
    "filter_list=[\"AGE\",\"LANE_CNT\",\"AIRBAG_DEPLOYED\",\"PRIM_CONTRIBUTORY_CAUSE\",\"POSTED_SPEED_LIMIT\",\"NUM_UNITS\",\"TRAFFICWAY_TYPE\",  \n",
    "             \"SEC_CONTRIBUTORY_CAUSE\",\"FIRST_CRASH_TYPE\",\"MOST_SEVERE_INJURY\",\"LIGHTING_CONDITION\",\"SEX\",\"CRASH_DATE\",\n",
    "             \"CRASH_HOUR\",\"VEHICLE_YEAR\"]\n",
    "\n",
    "# Data that will be used in predictions\n",
    "modeling_data=data[filter_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-27T20:24:32.392840Z",
     "start_time": "2020-11-27T20:24:32.368615Z"
    }
   },
   "outputs": [],
   "source": [
    "# Split modeling data into raw train and test sets\n",
    "raw_train, raw_test = train_test_split(modeling_data, test_size=0.20, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Train Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-27T20:24:32.420160Z",
     "start_time": "2020-11-27T20:24:32.396282Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocessor(dataframe):\n",
    "    '''Preprocesses df and returns X and y ready for modeling (after imputation of numericals!)'''\n",
    "    df = dataframe.copy()\n",
    "    \n",
    "    # Prepare data for missing value imputation\n",
    "    df.loc[df[\"LIGHTING_CONDITION\"] == \"UNKNOWN\", \"LIGHTING_CONDITION\"] = np.nan\n",
    "    df.loc[df[\"TRAFFICWAY_TYPE\"] == \"UNKNOWN\",\"TRAFFICWAY_TYPE\"] = np.nan\n",
    "    df.loc[df[\"AIRBAG_DEPLOYED\"] == \"DEPLOYMENT UNKNOWN\",\"AIRBAG_DEPLOYED\"] = np.nan\n",
    "    df.fillna({'LIGHTING_CONDITION': 'DAYLIGHT', 'TRAFFICWAY_TYPE': 'NOT DIVIDED',\n",
    "               'SEX': 'UNABLE TO DETERMINE', 'AIRBAG_DEPLOYED': 'UNABLE TO DETERMINE'}, inplace=True)\n",
    "    \n",
    "    # Remove rows missing most severe injury results\n",
    "    drop_rows = ['MOST_SEVERE_INJURY']\n",
    "    df.dropna(how ='any', subset = drop_rows, inplace = True)\n",
    "    \n",
    "    # Handle numerical features\n",
    "    df['VEHICLE_YEAR'] = pd.to_numeric(df['VEHICLE_YEAR'])\n",
    "    df['NUM_UNITS'] = pd.to_numeric(df['NUM_UNITS'])\n",
    "    df[\"POSTED_SPEED_LIMIT\"] = pd.to_numeric(df[\"POSTED_SPEED_LIMIT\"])\n",
    "    df[\"AGE\"] = pd.to_numeric(df[\"AGE\"])\n",
    "    \n",
    "    df['LANE_CNT'] = pd.to_numeric(df['LANE_CNT'])    \n",
    "    df['LANE_CNT'].fillna(2, inplace=True)\n",
    "    df.loc[(df['LANE_CNT'] > 6),'LANE_CNT'] = 6\n",
    "    \n",
    "    # Function definitions\n",
    "    def injury(x): \n",
    "        if any(s in x for s in [\"FATAL\",\"NONINCAPACITATING INJURY\",\"INCAPACITATING INJURY\"]):\n",
    "            return \"INJURED\"\n",
    "        else:\n",
    "            return \"NOT INJURED\"\n",
    "    \n",
    "    def airbag(x):\n",
    "        if (\"DEPLOY\" in x) and (\"UNKNOWN\" not in x):\n",
    "            if \"NOT\" in x:\n",
    "                return \"NOT DEPLOYED\"\n",
    "            else:\n",
    "                return \"DEPLOYED\"\n",
    "        else:\n",
    "            return x\n",
    "\n",
    "    def crash_hour(x):\n",
    "        if  2 <= x < 8:\n",
    "            return \"Early_morning\"\n",
    "        elif 8 <= x < 12:\n",
    "            return \"Morning\"\n",
    "        elif 12 <= x < 18:\n",
    "            return \"Afternoon\"\n",
    "        else:\n",
    "            return \"Night\"\n",
    "  \n",
    "    def traffic_way(x):\n",
    "        if (\"NOT\" in x) or (\"ONE-WAY\" in x):\n",
    "            return \"NOT_DIVIDED\"\n",
    "        else:\n",
    "            return \"DIVIDED\"\n",
    "    \n",
    "    # Feature Engineering\n",
    "    df[\"INJURY\"] = df[\"MOST_SEVERE_INJURY\"].apply(lambda x: injury(x))\n",
    "    df[\"AIRBAG_DEPLOYED\"] = df[\"AIRBAG_DEPLOYED\"].apply(lambda x: airbag(x))\n",
    "    df[\"CRASH_HOUR\"] = df[\"CRASH_HOUR\"].apply(lambda x: crash_hour(int(x)))\n",
    "    df[\"TRAFFICWAY_TYPE\"] = df[\"TRAFFICWAY_TYPE\"].apply(lambda x: traffic_way(x))\n",
    "    \n",
    "    df[\"VEHICLE_AGE\"] = df[\"CRASH_DATE\"].dt.year-df[\"VEHICLE_YEAR\"]\n",
    "    df.loc[df[\"VEHICLE_AGE\"] < 0, \"VEHICLE_AGE\"] = 0\n",
    "    df.drop([\"VEHICLE_YEAR\", \"CRASH_DATE\", \"MOST_SEVERE_INJURY\"], axis=1, inplace=True)\n",
    "    \n",
    "    # Splitting df into X and y\n",
    "    y = df[\"INJURY\"]\n",
    "    X = df.drop([\"INJURY\"], axis=1)\n",
    "    \n",
    "    # Binarize y\n",
    "    from sklearn.preprocessing import label_binarize\n",
    "    y = preprocessing.label_binarize(y, classes=['NOT INJURED', 'INJURED'])\n",
    "    \n",
    "    # One-Hot Encoding\n",
    "    X = pd.get_dummies(X, columns = X.select_dtypes(['object']).columns)\n",
    "    dummies_to_drop = X.columns[X.columns.str.contains(\"UNABLE|UNKNOWN|NOT APPLICABLE|OTHER\")]\n",
    "    X = X.loc[:, ~X.columns.isin(dummies_to_drop)]\n",
    "      \n",
    "    return(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-27T20:24:46.292300Z",
     "start_time": "2020-11-27T20:24:45.874412Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Preprocess train set\n",
    "X_train, y_train = preprocessor(raw_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-21T21:45:39.109Z"
    }
   },
   "outputs": [],
   "source": [
    "# Fit imputer and impute missing values on train set \n",
    "from sklearn.impute import KNNImputer\n",
    "imputer = KNNImputer(n_neighbors = 5)\n",
    "df = pd.DataFrame(imputer.fit_transform(X_train), columns = X_train.columns)\n",
    "X_train = df.copy()\n",
    "X_train = np.round(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-21T21:45:39.112Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train.isna().any().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-21T21:45:39.114Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Preprocess test set\n",
    "X_test, y_test = preprocessor(raw_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-21T21:45:39.117Z"
    }
   },
   "outputs": [],
   "source": [
    "# Add two trivial features of train set that doesn't exist in test set in order to use pre-fit imputer\n",
    "X_test[\"PRIM_CONTRIBUTORY_CAUSE_OBSTRUCTED CROSSWALKS\"] = 0\n",
    "X_test[\"SEC_CONTRIBUTORY_CAUSE_PASSING STOPPED SCHOOL BUS\"] = 0\n",
    "X_test = X_test[X_train.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-21T21:45:39.119Z"
    }
   },
   "outputs": [],
   "source": [
    "# Impute missing values on test set by pre-fit imputer object \n",
    "df = pd.DataFrame(imputer.transform(X_test), columns = X_test.columns)\n",
    "X_test = df.copy()\n",
    "X_test = np.round(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-21T21:45:39.122Z"
    }
   },
   "outputs": [],
   "source": [
    "X_test.isna().any().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing EDA Train Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-27T20:26:03.290953Z",
     "start_time": "2020-11-27T20:26:03.254864Z"
    }
   },
   "outputs": [],
   "source": [
    "def eda_preprocessor(dataframe):\n",
    "    '''Preprocesses and returns the entire train set for EDA'''\n",
    "    \n",
    "    df = dataframe.copy()\n",
    "    \n",
    "    # Split data into train test with exact indexing\n",
    "    train, test = train_test_split(df, test_size=0.20, random_state=42, shuffle=True)\n",
    "    \n",
    "    # Feature reduction\n",
    "    drop=[\"CRASH_DATE_EST_I\", \"REPORT_TYPE\", \"CRASH_DATE_EST_I\", \"REPORT_TYPE\", \"DATE_POLICE_NOTIFIED\",\n",
    "          \"BEAT_OF_OCCURRENCE\", \"PHOTOS_TAKEN_I\", \"STATEMENTS_TAKEN_I\", \"WORK_ZONE_TYPE\", \"WORKERS_PRESENT_I\", \n",
    "          \"INJURIES_NO_INDICATION\", \"INJURIES_UNKNOWN\", \"CRASH_DAY_OF_WEEK\", \"CRASH_MONTH\", \"RD_NO\", \"VEHICLE_ID\", \n",
    "          \"CRASH_RECORD_ID\", \"SEAT_NO\", \"STATE\", \"ZIPCODE\", \"DRIVERS_LICENSE_STATE\", \"PERSON_ID\", \"DRIVERS_LICENSE_CLASS\", \n",
    "          \"INJURY_CLASSIFICATION\", \"HOSPITAL\", \"EMS_AGENCY\", \"EMS_RUN_NO\", \"PEDPEDAL_LOCATION\", \"LOCATION\",\n",
    "          \"DAMAGE\", \"CRASH_TYPE\", \"MODEL\", \"BAC_RESULT\", \"CRASH_UNIT_ID\", \"RD_NO\", \"UNIT_NO\", \"UNIT_TYPE\", \n",
    "          \"VEHICLE_ID\", \"CMRC_VEH_I\", \"MAKE\", \"TOWED_I\", \"FIRE_I\", \"TOWED_BY\", \"STREET_NO\",\"STREET_NAME\",\n",
    "          \"TOWED_TO\", \"AREA_00_I\", \"AREA_01_I\", \"AREA_02_I\", \"AREA_03_I\", \"AREA_04_I\", \"AREA_05_I\", \"AREA_06_I\", \n",
    "          \"AREA_07_I\", \"AREA_08_I\", \"AREA_09_I\", \"AREA_10_I\", \"AREA_11_I\", \"AREA_12_I\", \"AREA_99_I\", \"CMV_ID\", \n",
    "          \"USDOT_NO\", \"CCMC_NO\", \"ILCC_NO\", \"COMMERCIAL_SRC\", \"GVWR\", \"CARRIER_NAME\", \"CARRIER_STATE\", \n",
    "          \"CARRIER_CITY\", \"HAZMAT_PLACARDS_I\", \"HAZMAT_NAME\", \"UN_NO\", \"HAZMAT_PRESENT_I\", \"HAZMAT_REPORT_I\",\n",
    "          \"HAZMAT_REPORT_NO\", \"MCS_REPORT_I\", \"MCS_REPORT_NO\", \"HAZMAT_VIO_CAUSE_CRASH_I\", \"MCS_VIO_CAUSE_CRASH_I\", \n",
    "          \"IDOT_PERMIT_NO\", \"WIDE_LOAD_I\", \"TRAILER1_WIDTH\", \"TRAILER2_WIDTH\", \"TRAILER1_LENGTH\", \"TRAILER2_LENGTH\", \n",
    "          \"TOTAL_VEHICLE_LENGTH\", \"AXLE_CNT\", \"VEHICLE_CONFIG\", \"CARGO_BODY_TYPE\", \"LOAD_TYPE\", \"HAZMAT_OUT_OF_SERVICE_I\",\n",
    "          \"INJURIES_REPORTED_NOT_EVIDENT\", \"INJURIES_NON_INCAPACITATING\", #\"INJURIES_FATAL\",\"INJURIES_INCAPACITATING\",\n",
    "          \"MCS_OUT_OF_SERVICE_I\", \"HAZMAT_CLASS\"]\n",
    "    \n",
    "    train = train.loc[:, ~train.columns.isin(drop)]\n",
    "    \n",
    "    \n",
    "    # Prepare data for missing value imputation\n",
    "    train.loc[train[\"TRAFFIC_CONTROL_DEVICE\"]==\"UNKNOWN\",\"TRAFFIC_CONTROL_DEVICE\"]=np.nan\n",
    "    train.loc[train[\"DEVICE_CONDITION\"]==\"UNKNOWN\",\"DEVICE_CONDITION\"]=np.nan\n",
    "    train.loc[train[\"WEATHER_CONDITION\"]==\"UNKNOWN\",\"WEATHER_CONDITION\"]=np.nan\n",
    "    train.loc[train[\"LIGHTING_CONDITION\"]==\"UNKNOWN\",\"LIGHTING_CONDITION\"]=np.nan\n",
    "    train.loc[train[\"TRAFFICWAY_TYPE\"]==\"UNKNOWN\",\"TRAFFICWAY_TYPE\"]=np.nan\n",
    "    train.loc[train[\"ROADWAY_SURFACE_COND\"]==\"UNKNOWN\",\"ROADWAY_SURFACE_COND\"]=np.nan\n",
    "    train.loc[train[\"ROAD_DEFECT\"]==\"UNKNOWN\",\"ROAD_DEFECT\"]=np.nan\n",
    "\n",
    "    train.loc[train[\"VEHICLE_DEFECT\"]==\"UNKNOWN\",\"VEHICLE_DEFECT\"]=np.nan\n",
    "    train.loc[train[\"VEHICLE_TYPE\"]==\"UNKNOWN/NA\",\"VEHICLE_TYPE\"]=np.nan\n",
    "    train.loc[train[\"TRAVEL_DIRECTION\"]==\"UNKNOWN\",\"TRAVEL_DIRECTION\"]=np.nan\n",
    "    train.loc[train[\"MANEUVER\"]==\"UNKNOWN/NA\",\"MANEUVER\"]=np.nan\n",
    "\n",
    "    train.loc[train[\"SAFETY_EQUIPMENT\"]==\"USAGE UNKNOWN\",\"SAFETY_EQUIPMENT\"]=np.nan\n",
    "    train.loc[train[\"AIRBAG_DEPLOYED\"]==\"DEPLOYMENT UNKNOWN\",\"AIRBAG_DEPLOYED\"]=np.nan\n",
    "    train.loc[train[\"EJECTION\"]==\"UNKNOWN\",\"EJECTION\"]=np.nan\n",
    "    train.loc[train[\"DRIVER_ACTION\"]==\"UNKNOWN\",\"DRIVER_ACTION\"]=np.nan\n",
    "    train.loc[train[\"DRIVER_VISION\"]==\"UNKNOWN\",\"DRIVER_VISION\"]=np.nan\n",
    "    train.loc[train[\"PHYSICAL_CONDITION\"]==\"UNKNOWN\",\"PHYSICAL_CONDITION\"]=np.nan\n",
    "    train.loc[train[\"PEDPEDAL_ACTION\"]==\"UNKNOWN/NA\",\"PEDPEDAL_ACTION\"]=np.nan\n",
    "    \n",
    "    \n",
    "    # Mıssing Value Imputation\n",
    "    train.fillna({\n",
    "        'TRAFFIC_CONTROL_DEVICE': 'NO CONTROLS',\n",
    "        'DEVICE_CONDITION': 'NO CONTROLS',\n",
    "        'WEATHER_CONDITION': 'CLEAR',\n",
    "        'LIGHTING_CONDITION': 'DAYLIGHT', # ??\n",
    "        'TRAFFICWAY_TYPE': 'NOT DIVIDED', # ??\n",
    "        'ROADWAY_SURFACE_COND': 'NO DEFECTS',\n",
    "        'ROAD_DEFECT': 'CLEAR',\n",
    "        'INTERSECTION_RELATED_I': 'N',\n",
    "    \n",
    "        'NOT_RIGHT_OF_WAY_I': 'N',\n",
    "        'HIT_AND_RUN_I': 'N',\n",
    "        'DOORING_I': 'N',\n",
    "        'WORK_ZONE_I': 'N',\n",
    "        'NUM_PASSENGERS': 0,\n",
    "        'LIC_PLATE_STATE': 'IL',\n",
    "        'VEHICLE_DEFECT': 'UNABLE TO DETERMINE',\n",
    "        'VEHICLE_TYPE': 'OTHER',\n",
    "\n",
    "        'VEHICLE_USE': 'OTHER',\n",
    "        'TRAVEL_DIRECTION': 'N',\n",
    "        'MANEUVER': 'OTHER',\n",
    "        'OCCUPANT_CNT': 0,\n",
    "        'EXCEED_SPEED_LIMIT_I': 'N',\n",
    "        'FIRST_CONTACT_POINT': 'OTHER',\n",
    "        'PERSON_TYPE': 'UNABLE TO DETERMINE',\n",
    "        'CITY': 'OTHER',\n",
    "\n",
    "        'SEX': 'UNABLE TO DETERMINE',\n",
    "        'AIRBAG_DEPLOYED': 'UNABLE TO DETERMINE',\n",
    "        'EJECTION': 'UNABLE TO DETERMINE',\n",
    "        'DRIVER_ACTION': 'OTHER',\n",
    "        'DRIVER_VISION': 'OTHER',\n",
    "        'PHYSICAL_CONDITION': 'UNABLE TO DETERMINE',\n",
    "        'PEDPEDAL_ACTION': 'UNABLE TO DETERMINE',\n",
    "        'PEDPEDAL_VISIBILITY': 'UNABLE TO DETERMINE',\n",
    "\n",
    "        'CELL_PHONE_USE': 'UNABLE TO DETERMINE',\n",
    "        'SAFETY_EQUIPMENT': 'UNABLE TO DETERMINE',\n",
    "        'BAC_RESULT VALUE': 0\n",
    "    }, inplace=True)\n",
    "    \n",
    "    \n",
    "    # Drop rows with missing values in these features\n",
    "    drop_rows = ['INJURIES_TOTAL', 'LATITUDE', 'MOST_SEVERE_INJURY']\n",
    "    train.dropna(how = 'any', subset = drop_rows, inplace = True)\n",
    "    \n",
    "\n",
    "    # Handle numerical features\n",
    "    train['LANE_CNT'] = pd.to_numeric(train['LANE_CNT'])\n",
    "    train['VEHICLE_YEAR'] = pd.to_numeric(train['VEHICLE_YEAR'])\n",
    "    train['NUM_UNITS'] = pd.to_numeric(train['NUM_UNITS'])\n",
    "    train[\"POSTED_SPEED_LIMIT\"] = pd.to_numeric(train[\"POSTED_SPEED_LIMIT\"])\n",
    "    train[\"AGE\"] = pd.to_numeric(train[\"AGE\"])\n",
    "    train[\"INJURIES_FATAL\"] = pd.to_numeric(train[\"INJURIES_FATAL\"])\n",
    "    train[\"INJURIES_INCAPACITATING\"] = pd.to_numeric(train[\"INJURIES_INCAPACITATING\"])\n",
    "    train[\"INJURIES_TOTAL\"] = pd.to_numeric(train[\"INJURIES_TOTAL\"])\n",
    "    \n",
    "    train['TOTAL_FATAL'] = train['INJURIES_FATAL'] + train['INJURIES_INCAPACITATING']\n",
    "    train['TOTAL_FATAL'] = pd.to_numeric(train['TOTAL_FATAL'])\n",
    "\n",
    "    train['LANE_CNT'] = pd.to_numeric(train['LANE_CNT'])    \n",
    "    train['LANE_CNT'].fillna(2, inplace=True)\n",
    "    train.loc[(train['LANE_CNT'] > 6),'LANE_CNT'] = 6\n",
    "    \n",
    "    \n",
    "    # Function definitions\n",
    "    def injury(x): \n",
    "        if any(s in x for s in [\"FATAL\",\"NONINCAPACITATING INJURY\",\"INCAPACITATING INJURY\"]):\n",
    "            return \"INJURED\"\n",
    "        else:\n",
    "            return \"NOT INJURED\"\n",
    "        \n",
    "    def fatalities(x): \n",
    "        if any(s in x for s in [\"FATAL\"]):\n",
    "            return \"FATAL\"\n",
    "        else:\n",
    "            return \"NOT FATAL\"\n",
    "    \n",
    "    def airbag(x):\n",
    "        if (\"DEPLOY\" in x) and (\"UNKNOWN\" not in x):\n",
    "            if \"NOT\" in x:\n",
    "                return \"NOT DEPLOYED\"\n",
    "            else:\n",
    "                return \"DEPLOYED\"\n",
    "        else:\n",
    "            return x\n",
    "  \n",
    "    def traffic_way(x):\n",
    "        if (\"NOT\" in x) or (\"ONE-WAY\" in x):\n",
    "            return \"NOT_DIVIDED\"\n",
    "        else:\n",
    "            return \"DIVIDED\"\n",
    "        \n",
    "    def contact_point(x):\n",
    "        if \"FRONT\" in x:\n",
    "            return \"FRONT\"\n",
    "        elif \"SIDE\" in x:\n",
    "            return \"SIDE\"\n",
    "        elif \"REAR\" in x:\n",
    "            return \"REAR\"\n",
    "        else:\n",
    "            return \"OTHER\"\n",
    "    \n",
    "    def equip_used(x):\n",
    "        if (\"USED\" in x) or (\"HELMET\" in x) or (\"NONE PRESENT\" in x):\n",
    "            if any(s in x for s in [\"NOT\",\"IMPROPER\",\"NONE PRESENT\"]):\n",
    "                return \"DID NOT USE SAFETY EQUIP\"\n",
    "            else:\n",
    "                return \"USED SAFETY EQUIP\"\n",
    "        else:\n",
    "            return x\n",
    "\n",
    "    def airbag(x):\n",
    "        if (\"DEPLOY\" in x) and (\"UNKNOWN\" not in x):\n",
    "            if \"NOT\" in x:\n",
    "                return \"NOT DEPLOYED\"\n",
    "            else:\n",
    "                return \"DEPLOYED\"\n",
    "        else:\n",
    "            return x\n",
    "    \n",
    "    def crash_hour(x):\n",
    "        if  2 <= x < 8:\n",
    "            return \"Early_morning\"\n",
    "        elif 8 <= x < 12:\n",
    "            return \"Morning\"\n",
    "        elif 12 <= x < 18:\n",
    "            return \"Afternoon\"\n",
    "        else:\n",
    "            return \"Night\"\n",
    "\n",
    "    def traffic_control(x):\n",
    "        if (\"NO CONTROLS\" in x) or (\"UNKNOWN\" in x) or (\"OTHER\" in x):\n",
    "            return \"NO_SIGN\"\n",
    "        else:\n",
    "            return \"SIGN\"\n",
    "    \n",
    "    def location(x1,x2):\n",
    "        if (41.84 <= float(x1) <= 41.9100064) and (-87.7421459 <= float(x2) <= -87.50):\n",
    "            return \"Downtown\"\n",
    "        else:\n",
    "            return \"Not Downtown\"\n",
    "\n",
    "        \n",
    "    # Feature engineering\n",
    "    train[\"INJURY\"] = train[\"MOST_SEVERE_INJURY\"].apply(lambda x: injury(x))\n",
    "    train[\"FATALITIES\"] = train[\"MOST_SEVERE_INJURY\"].apply(lambda x: fatalities(x))\n",
    "    train[\"AIRBAG_DEPLOYED\"] = train[\"AIRBAG_DEPLOYED\"].apply(lambda x: airbag(x))\n",
    "    train[\"CRASH_HOUR\"] = train[\"CRASH_HOUR\"].apply(lambda x: crash_hour(int(x)))\n",
    "    train[\"TRAFFICWAY_TYPE\"] = train[\"TRAFFICWAY_TYPE\"].apply(lambda x: traffic_way(x))\n",
    "    train[\"FIRST_CONTACT_POINT\"] = train[\"FIRST_CONTACT_POINT\"].apply(lambda x: contact_point(x))\n",
    "    train[\"MANEUVER\"] = train[\"MANEUVER\"].apply(lambda x: \"TURN\" if \"TURN\" in x else(\"LANE\" if any(s in x for s in [\"LANE\",\"OVER\",\"ENTER\"]) else x))\n",
    "    train[\"MANEUVER\"] = train[\"MANEUVER\"].apply(lambda x: \"OTHER\" if all(s not in x for s in [\"AHEAD\",\"TURN\",\"UNKNOWN\",\"LANE\",\"BACKING\"]) else x)\n",
    "    train[\"SAFETY_EQUIPMENT\"] = train[\"SAFETY_EQUIPMENT\"].apply(lambda x: equip_used(x))\n",
    "    train[\"AIRBAG_DEPLOYED\"] = train[\"AIRBAG_DEPLOYED\"].apply(lambda x: airbag(x))\n",
    "    train[\"TRAFFIC_CONTROL_DEVICE\"]= train[\"TRAFFIC_CONTROL_DEVICE\"].apply(lambda x: traffic_control(x))\n",
    "    train[\"Location\"] = train.apply(lambda x: location(x[\"LATITUDE\"], x[\"LONGITUDE\"]), axis = 1)\n",
    "    \n",
    "    train[\"VEHICLE_AGE\"] = train[\"CRASH_DATE\"].dt.year-train[\"VEHICLE_YEAR\"]\n",
    "    train.loc[train[\"VEHICLE_AGE\"] < 0, \"VEHICLE_AGE\"] = 0\n",
    "    train.drop([\"VEHICLE_YEAR\", \"MOST_SEVERE_INJURY\"], axis=1, inplace=True)  # \"CRASH_DATE\" for Tony\n",
    "     \n",
    "    # Return only train set for EDA purposes     \n",
    "    return(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-27T20:26:07.957558Z",
     "start_time": "2020-11-27T20:26:05.648325Z"
    }
   },
   "outputs": [],
   "source": [
    "train = eda_preprocessor(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-27T20:27:18.578034Z",
     "start_time": "2020-11-27T20:27:18.565188Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NOT INJURED    0.891667\n",
       "INJURED        0.108333\n",
       "Name: INJURY, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.INJURY.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison of Imputation Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-21T21:45:39.129Z"
    }
   },
   "outputs": [],
   "source": [
    "# To use the experimental IterativeImputer, we need to explicitly ask for it:\n",
    "from sklearn.experimental import enable_iterative_imputer  # noqa\n",
    "from sklearn.impute import SimpleImputer, KNNImputer, IterativeImputer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-21T21:45:39.132Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train_imp, y_train_imp = preprocessor(raw_train)\n",
    "\n",
    "random_final = RandomForestClassifier(n_estimators=1000, min_samples_split=15, min_samples_leaf=5, \n",
    "                                      max_features='log2', max_depth=13, criterion='entropy', random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-21T21:45:39.134Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_scores_for_imputer(imputer, X_missing, y_missing, scoring='recall', cv=5):\n",
    "    estimator = make_pipeline(imputer, random_final)\n",
    "    impute_scores = cross_val_score(estimator, X_missing, y_missing, scoring=scoring, cv=cv)\n",
    "    return np.mean(impute_scores), np.std(impute_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-21T21:45:39.137Z"
    }
   },
   "outputs": [],
   "source": [
    "imputer_recall_mean = np.zeros(3)\n",
    "imputer_recall_std = np.zeros(3)\n",
    "\n",
    "#imputer_recall_mean[0], imputer_recall_std[0] = get_scores_for_imputer(X_train_imp, y_train_imp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-21T21:45:39.139Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_impute_median_score(X_missing, y_missing, scoring='recall', cv=5):\n",
    "    imputer = SimpleImputer(missing_values=np.nan, strategy=\"median\", add_indicator=True)\n",
    "    median_impute_scores = get_scores_for_imputer(imputer, X_missing, y_missing, scoring=scoring, cv=cv)\n",
    "    return np.mean(median_impute_scores), np.std(median_impute_scores)\n",
    "\n",
    "imputer_recall_mean[0], imputer_recall_std[0] = get_impute_median_score(X_train_imp, y_train_imp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-21T21:45:39.141Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_impute_knn_score(X_missing, y_missing, scoring='recall', cv=5):\n",
    "    imputer = KNNImputer(missing_values=np.nan, add_indicator=True)\n",
    "    knn_impute_scores = get_scores_for_imputer(imputer, X_missing, y_missing, scoring=scoring, cv=cv)\n",
    "    return np.mean(knn_impute_scores), np.std(knn_impute_scores)\n",
    "\n",
    "imputer_recall_mean[1], imputer_recall_std[1] = get_impute_knn_score(X_train_imp, y_train_imp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-21T21:45:39.144Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_impute_iterative_score(X_missing, y_missing, scoring='recall', cv=5):\n",
    "    imputer = IterativeImputer(missing_values=np.nan, add_indicator=True, random_state=0, \n",
    "                               n_nearest_features=5, sample_posterior=True)\n",
    "    iterative_impute_scores = get_scores_for_imputer(imputer, X_missing, y_missing, scoring=scoring, cv=cv)\n",
    "    return np.mean(iterative_impute_scores), np.std(iterative_impute_scores)\n",
    "\n",
    "imputer_recall_mean[2], imputer_recall_std[2] = get_impute_iterative_score(X_train_imp, y_train_imp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-21T21:45:39.146Z"
    }
   },
   "outputs": [],
   "source": [
    "# Box-cox transformation (0=log)\n",
    "#from scipy.stats import boxcox\n",
    "#X_train_imp_np = np.round(X_train_imp)\n",
    "#y_train_imp_np = np.round(y_train_imp)\n",
    "\n",
    "#from scipy.special import inv_boxcox\n",
    "#X_bc, fitted_lambda = ss.boxcox(np.round(X_train_imp.values), lmbda=None)\n",
    "#X_bc = inv_boxcox(X_bc, fitted_lambda)\n",
    "\n",
    "#y_bc, fitted_lambda = ss.boxcox(np.round(X_train_imp.values), lmbda=None)\n",
    "#y_bc = inv_boxcox(y_bc, fitted_lambda)\n",
    "\n",
    "#imputer_recall_mean[2], imputer_recall_std[2] = get_impute_iterative_score(X_bc, y_bc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-21T21:45:39.149Z"
    }
   },
   "outputs": [],
   "source": [
    "imputer_recall_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-21T21:45:39.151Z"
    }
   },
   "outputs": [],
   "source": [
    "imputer_recall_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-21T21:45:39.153Z"
    }
   },
   "outputs": [],
   "source": [
    "imputer_recall_mean_neg = imputer_recall_mean * -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-21T21:45:39.156Z"
    }
   },
   "outputs": [],
   "source": [
    "x_labels = ['Median imputation', 'KNN Imputation', 'Iterative Imputation']\n",
    "n_bars = len(imputer_recall_mean_neg)\n",
    "xval = np.arange(n_bars)\n",
    "\n",
    "colors = ['r', 'g', 'b', 'orange', 'black']\n",
    "\n",
    "# plot results\n",
    "plt.figure(figsize=(16, 8))\n",
    "ax1 = plt.subplot(121)\n",
    "for j in xval:\n",
    "    ax1.barh(j, imputer_recall_mean_neg[j], #xerr=imputer_recall_std[j],\n",
    "             color=colors[j], alpha=0.6, align='center')\n",
    "\n",
    "ax1.set_title('Comparison of Imputation Techniques')\n",
    "ax1.set_xlim(left = np.min(imputer_recall_mean_neg) * 0.9, right = np.max(imputer_recall_mean_neg) * 1.1)\n",
    "ax1.set_yticks(xval)\n",
    "ax1.set_xlabel('Recall')\n",
    "ax1.invert_yaxis()\n",
    "ax1.set_yticklabels(x_labels)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-21T21:45:39.158Z"
    }
   },
   "outputs": [],
   "source": [
    "drop_list = [\"LATITUDE\", \"LONGITUDE\", \"INJURIES_TOTAL\", \"CRASH_DATE\", \"INJURY\", \"FATALITIES\", \"TOTAL_FATAL\", \n",
    "             \"INJURIES_INCAPACITATING\", \"INJURIES_INCAPACITATING\", \"INJURIES_FATAL\"]\n",
    "train_new = train.drop(drop_list, axis=1)\n",
    "train_new = train_new[(train_new.PRIM_CONTRIBUTORY_CAUSE != 'UNABLE TO DETERMINE') & (train_new.PRIM_CONTRIBUTORY_CAUSE != 'NOT APPLICABLE')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-21T21:45:39.160Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train_cat = train_new.drop([\"PRIM_CONTRIBUTORY_CAUSE\"],axis=1).reset_index(drop=True)\n",
    "y_train_cat = train_new[\"PRIM_CONTRIBUTORY_CAUSE\"]\n",
    "X_train_cat, X_val_cat, y_train_cat, y_val_cat = train_test_split(X_train_cat, y_train_cat, test_size=0.25, random_state=42, stratify=y_train_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-21T21:45:39.163Z"
    }
   },
   "outputs": [],
   "source": [
    "categorical_features_indices = np.where(X_train_cat.dtypes == object)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-21T21:45:39.165Z"
    }
   },
   "outputs": [],
   "source": [
    "from catboost import Pool, CatBoostClassifier\n",
    "\n",
    "train_dataset = Pool(data = X_train_cat, label = y_train_cat, cat_features = categorical_features_indices)\n",
    "eval_dataset = Pool(data=X_val_cat, label=y_val_cat, cat_features=categorical_features_indices)\n",
    "\n",
    "# Initialize CatBoostClassifier\n",
    "model = CatBoostClassifier(iterations=10, learning_rate=1, depth=2, loss_function='MultiClass')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-21T21:45:39.167Z"
    }
   },
   "outputs": [],
   "source": [
    "model.fit(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-21T21:45:39.169Z"
    }
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(eval_dataset)\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(confusion_matrix(y_val_cat, y_pred))\n",
    "\n",
    "# Print the precision and recall, among other metrics\n",
    "print(classification_report(y_val_cat, y_pred, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bootstrapped CIs for Model Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-21T21:45:39.172Z"
    }
   },
   "outputs": [],
   "source": [
    "# Random Undersampling on X and y train sets\n",
    "under = RandomUnderSampler(sampling_strategy=1)\n",
    "X_under, y_under = under.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-21T21:45:39.175Z"
    }
   },
   "outputs": [],
   "source": [
    "# Store n_bootstraps number of bootstrap samples of X and y dataframes in lists\n",
    "n_bootstraps = 1000\n",
    "\n",
    "bootstrap_X_train = []\n",
    "bootstrap_y_train = []\n",
    "for _ in range(n_bootstraps):\n",
    "    sample_X, sample_y = resample(X_under, y_under)\n",
    "    bootstrap_X_train.append(sample_X)\n",
    "    bootstrap_y_train.append(sample_y)\n",
    "    \n",
    "bootstrap_X_test = []\n",
    "bootstrap_y_test = []\n",
    "for _ in range(n_bootstraps):\n",
    "    sample_X, sample_y = resample(X_test, y_test)\n",
    "    bootstrap_X_test.append(sample_X)\n",
    "    bootstrap_y_test.append(sample_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-21T21:45:39.177Z"
    }
   },
   "outputs": [],
   "source": [
    "# Random Forest model with tuned hyperparameters\n",
    "random_final = RandomForestClassifier(n_estimators=1000, min_samples_split=15, min_samples_leaf=5, \n",
    "                                      max_features='log2', max_depth=13, criterion='entropy', random_state=0)\n",
    "\n",
    "# Predict n_bootstraps number of bootstrapped samples and store recall results\n",
    "recall_scores = []\n",
    "\n",
    "for index, (train, test) in enumerate(zip(bootstrap_X_train, bootstrap_X_test)):\n",
    "    model = random_final.fit(train, bootstrap_y_train[index])\n",
    "    y_pred = model.predict(test)\n",
    "    recall_scores.append(recall_score(bootstrap_y_test[index], y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision is how sure you are of your true positives while recall is how sure you are that you are not missing any positives.\n",
    "\n",
    "Recall value of 0.70 means that 3 of every 10 injuried people in reality are missed by our model and 7 labeled as injuried."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-21T21:45:39.179Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot scores\n",
    "plt.hist(recall_scores) # , bins=5 \n",
    "plt.show()\n",
    "\n",
    "# Confidence intervals\n",
    "alpha = 0.95\n",
    "p = ((1.0 - alpha) / 2.0) * 100\n",
    "lower = max(0.0, np.percentile(recall_scores, p))\n",
    "p = (alpha + ((1.0 - alpha) / 2.0)) * 100\n",
    "upper = min(1.0, np.percentile(recall_scores, p))\n",
    "\n",
    "print('%.1f confidence interval for recall %.1f%% and %.1f%% across %.d bootstrapped predictions.' % (alpha*100, lower*100, upper*100, n_bootstraps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-21T21:45:39.182Z"
    }
   },
   "outputs": [],
   "source": [
    "#elapsed = timeit.default_timer() - start_time\n",
    "#print('Total runtime is', round(elapsed, 2)/60, 'minutes.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Further Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of Injuries Fatalities "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- **14% of fatalities** and **10% of injuries** happened to **people aged over 60**.\n",
    "- **12% of fatalities** and **11% of injuries** happened in **vehicles aged over 15**.\n",
    "\n",
    "\n",
    "- **25% of fatalities** and **13% of injuries** happened to **cyclers with no contrasting clothing**.\n",
    "- **6% of injuries** happened to pedestrians or pedalists **while crossing the road**.\n",
    "- **22% of fatalities** happened where drivers were **failed to reduce speed**.\n",
    "- **22% of injuries** happened where drivers were **failed to yield right of way**.\n",
    "\n",
    "\n",
    "- **8% of fatalities** happened where drivers were **too fast for conditions**.\n",
    "- **16% of fatalities** and **35% of injuries** happened in which **cars were failed to deploy airbags**.\n",
    "- **14% of fatalities** and **13% of injuries** happened to **drivers failed to use safety equipment**.\n",
    "\n",
    "\n",
    "- **22% of fatalities** and **11% of injuries** happened to **pedestrians**.\n",
    "- **5% of fatalities** and **1% of injuries** happened in **the excess of speed limits**.\n",
    "\n",
    "\n",
    "- **55% of fatalities** and **33% of injuries** happened **at night accidents**.\n",
    "- **11% of fatalities** and **16% of injuries** happened in **wet roads**.\n",
    "- **39% of fatalities** and **47% of injuries** happened in **collisions straight ahead**.\n",
    "- **5% of fatalities** and **12% of injuries** happened in **a turn maneuver**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-21T21:45:39.184Z"
    }
   },
   "outputs": [],
   "source": [
    "train = eda_preprocessor(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-21T21:45:39.186Z"
    }
   },
   "outputs": [],
   "source": [
    "def injury_fatality_summarizer(col, df=train):\n",
    "    x=df[df['INJURY']=='INJURED'][col].value_counts(normalize=True).reset_index(name='injury')\n",
    "    y=df[df['FATALITIES']=='FATAL'][col].value_counts(normalize=True).reset_index(name='fatal')\n",
    "    \n",
    "    table=x.merge(y, how='inner', on=['index']).sort_values(['fatal','injury'], ascending=False)\n",
    "    table=table.rename(columns={'index':col, 'injury':'PERCENTAGE OF INJURIES', 'fatal':'PERCENTAGE OF FATALITIES'})\n",
    "    return(table[:12].round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-21T21:45:39.196Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from IPython.core import display as ICD\n",
    "\n",
    "for col in train.columns:\n",
    "    table = injury_fatality_summarizer(col)\n",
    "    ICD.display(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time-Series Findings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-18T11:01:39.755141Z",
     "start_time": "2020-11-18T11:01:39.739400Z"
    }
   },
   "source": [
    "**Overview Structure based on Time**\n",
    "\n",
    "- There is **at least 7 traffic crashes** in Chicago **on a daily basis**.\n",
    "\n",
    "\n",
    "- **At least 11 people** are injured in a traffic crash **every day**!\n",
    "\n",
    "\n",
    "- **Everyday, at least 1 person dies or faces with fatal injuries** in a traffic crash in Chicago!\n",
    "\n",
    "\n",
    "- **Death and serious injuries** from traffic crashes **increased by 8% by each year**!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-21T21:45:39.198Z"
    }
   },
   "outputs": [],
   "source": [
    "# Convert crash_data into time\n",
    "train['CRASH_DATE'] = pd.to_datetime(train.CRASH_DATE)\n",
    "train['CRASH_DATE_NEW'] = pd.to_datetime(train['CRASH_DATE']).dt.date\n",
    "#train['CRASH_DATE_NEW']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-21T21:45:39.201Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_new = train.copy()\n",
    "from datetime import datetime, date\n",
    "#df[df['CRASH_DATE_NEW'] == date(2020, 4, 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-21T21:45:39.203Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_new.groupby(['CRASH_DATE_NEW'])['TOTAL_FATAL'].sum().sort_values(ascending = True).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-21T21:45:39.205Z"
    }
   },
   "outputs": [],
   "source": [
    "train_new.groupby(['CRASH_DATE_NEW'])['INJURIES_TOTAL'].sum().sort_values(ascending = True).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-21T21:45:39.207Z"
    }
   },
   "outputs": [],
   "source": [
    "train_new['YEAR'] = train_new.CRASH_DATE.dt.year\n",
    "train_new['MONTH'] = train_new.CRASH_DATE.dt.month\n",
    "#train_new.YEAR.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-21T21:45:39.209Z"
    }
   },
   "outputs": [],
   "source": [
    "#plot data for Injuries Total\n",
    "fig, ax = plt.subplots(figsize=(15,7))\n",
    "train_new.groupby(['YEAR'])['TOTAL_FATAL'].sum().plot(ax = ax)\n",
    "\n",
    "#r = [1,3,5,7]\n",
    "#names = ['2017', '2018', '2019', '2020']\n",
    "plt.xticks(fontsize=14)\n",
    "#plt.yticks(fontsize=14)\n",
    "plt.xlabel('Year', fontsize=14)\n",
    "plt.ylabel('Total Number of Serious Injuries and Fatalities', fontsize=14)\n",
    "plt.title('Yearly Data for Serious Injuries and Fatalities', fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-21T21:45:39.211Z"
    }
   },
   "outputs": [],
   "source": [
    "#plot monthly data for Injuries Total\n",
    "fig, ax = plt.subplots(figsize=(15,7))\n",
    "train_new.groupby(['MONTH'])['INJURIES_TOTAL'].sum().plot(ax = ax)\n",
    "\n",
    "r = [2,4,6,8,10,12]\n",
    "names = ['February', 'April', 'June', 'August', 'October', 'December']\n",
    "plt.xticks(r, names, fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.ylabel('Total Number of Injuries and Fatalities', fontsize=14)\n",
    "plt.title('Monthly Data for Total Injuries', fontsize=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fatal Traffic Crashes By Travel Choice\n",
    "\n",
    "People in vehicles account for more than half of traffic crash fatalities each year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-21T21:45:39.214Z"
    }
   },
   "outputs": [],
   "source": [
    "df = train_new.groupby(['YEAR', 'PERSON_TYPE']).agg({'TOTAL_FATAL': 'sum'})\n",
    "df\n",
    "\n",
    "# Change: groupby state_office and divide by sum\n",
    "df1 = df.groupby(level=0).apply(lambda x:100 * x / float(x.sum()))\n",
    "df1.reset_index(inplace=True)\n",
    "df1=df1[df1['PERSON_TYPE'].isin(['BICYCLE','DRIVER','PEDESTRIAN'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-21T21:45:39.216Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-21T21:45:39.218Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "fig=plt.figure(figsize = (14,8))\n",
    "ax=fig.add_subplot(111)\n",
    "\n",
    "x = ['2017', '2018', '2019', '2020']\n",
    "ax.plot(x,df1[df1['PERSON_TYPE']=='DRIVER']['TOTAL_FATAL'],c='g',marker=(8,2,0),ls='--', linewidth=2,label='DRIVER')\n",
    "ax.plot(x,df1[df1['PERSON_TYPE']=='BICYCLE']['TOTAL_FATAL'],c='r',marker=\"v\",ls='-', linewidth=2,label='BICYCLE')\n",
    "ax.plot(x,df1[df1['PERSON_TYPE']=='PEDESTRIAN']['TOTAL_FATAL'],c='m',marker=\"o\",ls='--', linewidth=2,label='PEDESTRIAN')\n",
    "\n",
    "ax.set_xlabel(\"YEAR\")\n",
    "ax.set_ylabel(\"Percent\")\n",
    "ax.set_ylim(0,100)\n",
    "plt.legend(loc=1)\n",
    "plt.title(\"Fatalities Percentage Distribution over year\",fontsize=20)\n",
    "\n",
    "space = 5\n",
    "va = 'bottom'\n",
    " \n",
    "for i in range(0,3):\n",
    "    line = ax.lines[i]\n",
    "    for x_value, y_value in zip(line.get_xdata(), line.get_ydata()):\n",
    "        label = \"{:.2f}\".format(y_value)\n",
    "        ax.annotate(label,(x_value, y_value), xytext=(0, space), \n",
    "            textcoords=\"offset points\", ha='center', va=va)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-21T21:45:39.220Z"
    }
   },
   "outputs": [],
   "source": [
    "# from matplotlib import rc\n",
    " \n",
    "# plt.subplots(figsize=(18,12))\n",
    "    \n",
    "# y-axis in bold\n",
    "#rc('font', weight='bold')\n",
    " \n",
    "# Values of each group\n",
    "#bars1 = [94, 374, 370, 229]\n",
    "#bars2 = [15, 56, 131, 70]\n",
    "#bars3 = [3, 15, 19, 12]\n",
    " \n",
    "# Heights of bars1 + bars2\n",
    "#bars = np.add(bars1, bars2).tolist()\n",
    " \n",
    "# The position of the bars on the x-axis\n",
    "#r = [0,2,4,6]\n",
    " \n",
    "# Names of group and bar width\n",
    "#names = ['2017','2018','2019','2020']\n",
    "#barWidth = 1\n",
    " \n",
    "# Create brown bars\n",
    "#plt.bar(r, bars1, color='#7f6d5f', edgecolor='white', width=barWidth, label='PEOPLE IN VEHICLES')\n",
    "# Create green bars (middle), on top of the firs ones\n",
    "#plt.bar(r, bars2, bottom=bars1, color='#557f2d', edgecolor='white', width=barWidth, label='PEOPLE WALKING')\n",
    "# Create green bars (top)\n",
    "#plt.bar(r, bars3, bottom=bars, color='#2d7f5e', edgecolor='white', width=barWidth, label='PEOPLE BICYCLING')\n",
    " \n",
    "# Custom X axis\n",
    "#plt.xticks(r, names, fontweight='bold', fontsize=18)\n",
    "#plt.yticks(fontweight='bold', fontsize=18)\n",
    "#plt.xlabel(\"Year\", fontsize=20)\n",
    "#plt.ylabel(\"Number of Serious Injuries and Fatalities\", fontsize=20)\n",
    "#plt.legend(loc='upper left', frameon=False, fontsize=16)\n",
    " \n",
    "# Show graphic\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vulnerability of Roadway Users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- People walking are **7.5 times more likely** to be killed or seriously injured. \n",
    "\n",
    "- People bicycling are **6.2 times more likely** to be killed or seriously injured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-21T21:45:39.223Z"
    }
   },
   "outputs": [],
   "source": [
    "n_driver_inj=train_new.loc[(train_new[\"INJURY\"]=='INJURED')&(train_new[\"PERSON_TYPE\"]==\"DRIVER\"),:].shape[0]\n",
    "n_driver_acc=train_new.loc[train_new[\"PERSON_TYPE\"]==\"DRIVER\", :].shape[0]\n",
    "p_driver = round(n_driver_inj/n_driver_acc, 2)\n",
    "print('Probability of getting seriously injured or killed in an accident for', \n",
    "      '\\033[1m', 'a driver', '\\033[0m', 'is', '\\033[1m', p_driver, '%.', '\\033[0m')\n",
    "\n",
    "print()\n",
    "\n",
    "n_ped_inj=train_new.loc[(train_new[\"INJURY\"]=='INJURED')&(train_new[\"PERSON_TYPE\"]==\"PEDESTRIAN\"),:].shape[0]\n",
    "n_ped_acc=train_new.loc[train_new[\"PERSON_TYPE\"]==\"PEDESTRIAN\", :].shape[0]\n",
    "p_ped = round(n_ped_inj/n_ped_acc, 2)\n",
    "print('Probability of getting seriously injured or killed in an accident for', \n",
    "      '\\033[1m', 'a pedestrian', '\\033[0m', 'is', '\\033[1m', p_ped, '%.', '\\033[0m')\n",
    "\n",
    "print()\n",
    "\n",
    "n_bcycle_inj=train_new.loc[(train_new[\"INJURY\"]=='INJURED')&(train_new[\"PERSON_TYPE\"]==\"BICYCLE\"),:].shape[0]\n",
    "n_bcycle_acc=train_new.loc[train_new[\"PERSON_TYPE\"]==\"BICYCLE\", :].shape[0]\n",
    "p_bcycle = round(n_bcycle_inj/n_bcycle_acc, 2)\n",
    "print('Probability of getting seriously injured or killed in an accident for', \n",
    "      '\\033[1m', 'a cycler', '\\033[0m', 'is', '\\033[1m', p_bcycle, '%.', '\\033[0m')\n",
    "\n",
    "print()\n",
    "\n",
    "print('People walking are', '\\033[1m',  round(p_ped/p_driver, 2), 'times more likely', '\\033[0m', \n",
    "      'to be killed or seriously injured!')\n",
    "\n",
    "print()\n",
    "\n",
    "print('People bicycling are', '\\033[1m',  round(p_bcycle/p_driver, 2), 'times more likely', '\\033[0m', \n",
    "      'to be killed or seriously injured!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-21T21:45:39.225Z"
    }
   },
   "outputs": [],
   "source": [
    "print('\\033[1m', 'Probability of getting injured in an accident by Person Type', '\\033[0m')\n",
    "round((train_new[train_new['INJURY']=='INJURED']['PERSON_TYPE'].value_counts() / train_new.shape[train_new['PERSON_TYPE']=='INJURED'] * 100),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-21T21:45:39.227Z"
    }
   },
   "outputs": [],
   "source": [
    "print('\\033[1m', 'Number of Serious Injuries and Fatalities by Person Type', '\\033[0m')\n",
    "train_new.groupby(['PERSON_TYPE'])['TOTAL_FATAL'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-21T21:45:39.229Z"
    }
   },
   "outputs": [],
   "source": [
    "#train_new.shape[0]  #53178\n",
    "#train_new.loc(train_new['PERSON_TYPE'=='BIBCYCLE'], )['TOTAL_FATAL'].sum()\n",
    "print(train_new.TOTAL_FATAL.sum())\n",
    "train_new.loc[train['PERSON_TYPE'] == 'BICYCLE', 'TOTAL_FATAL'].sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-21T21:45:39.231Z"
    }
   },
   "outputs": [],
   "source": [
    "print(train_new.INJURIES_TOTAL.sum())\n",
    "\n",
    "print('\\033[1m', 'Number of Serious Injuries and Fatalities by Person Type', '\\033[0m')\n",
    "train_new.groupby(['PERSON_TYPE'])['INJURIES_TOTAL'].sum()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-21T21:45:39.233Z"
    }
   },
   "outputs": [],
   "source": [
    "print('\\033[1m', 'Number of Minor Injuries by Person Type', '\\033[0m')\n",
    "minor_injuries = train_new.groupby(['PERSON_TYPE'])['INJURIES_TOTAL'].sum() - train_new.groupby(['PERSON_TYPE'])['TOTAL_FATAL'].sum()\n",
    "minor_injuries.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-21T21:45:39.236Z"
    }
   },
   "outputs": [],
   "source": [
    "# Pie chart\n",
    "labels = ['SEVERE INJURIES', 'MINOR INJURIES']\n",
    "sizes = [1067, 8602]\n",
    "#colors\n",
    "colors = ['#ff9999','#66b3ff']\n",
    "\n",
    "\n",
    "fig1, ax1 = plt.subplots(figsize=(5,5))\n",
    "ax1.pie(sizes, colors = colors, labels=labels, autopct='%1.1f%%', startangle=90)\n",
    "#draw circle\n",
    "centre_circle = plt.Circle((0,0),0.70,fc='white')\n",
    "fig = plt.gcf()\n",
    "fig.gca().add_artist(centre_circle)\n",
    "\n",
    "plt.title('PEOPLE IN VEHICLES', fontsize=15)\n",
    "\n",
    "\n",
    "# Equal aspect ratio ensures that pie is drawn as a circle\n",
    "ax1.axis('equal')  \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-21T21:45:39.238Z"
    }
   },
   "outputs": [],
   "source": [
    "# Pie chart\n",
    "labels = ['SEVERE INJURIES', 'MINOR INJURIES']\n",
    "sizes = [272, 862]\n",
    "#colors\n",
    "colors = ['#ff9999','#66b3ff']\n",
    "\n",
    "\n",
    "fig1, ax1 = plt.subplots(figsize=(6,6))\n",
    "ax1.pie(sizes, colors = colors, labels=labels, autopct='%1.1f%%', startangle=90)\n",
    "#draw circle\n",
    "centre_circle = plt.Circle((0,0),0.70,fc='white')\n",
    "fig = plt.gcf()\n",
    "fig.gca().add_artist(centre_circle)\n",
    "\n",
    "plt.title('PEDESTRIAN', fontsize=15)\n",
    "\n",
    "\n",
    "# Equal aspect ratio ensures that pie is drawn as a circle\n",
    "ax1.axis('equal')  \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-21T21:45:39.240Z"
    }
   },
   "outputs": [],
   "source": [
    "# Pie chart\n",
    "labels = ['SEVERE INJURIES', 'MINOR INJURIES']\n",
    "sizes = [49, 249]\n",
    "#colors\n",
    "colors = ['#ff9999','#66b3ff']\n",
    "\n",
    "\n",
    "fig1, ax1 = plt.subplots(figsize=(5.5, 5.5))\n",
    "ax1.pie(sizes, colors = colors, labels=labels, autopct='%1.1f%%', startangle=90)\n",
    "#draw circle\n",
    "centre_circle = plt.Circle((0,0),0.70,fc='white')\n",
    "fig = plt.gcf()\n",
    "fig.gca().add_artist(centre_circle)\n",
    "\n",
    "plt.title('PEOPLE BYCYCLING', fontsize=15)\n",
    "\n",
    "\n",
    "# Equal aspect ratio ensures that pie is drawn as a circle\n",
    "ax1.axis('equal')  \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More Impacted Communities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-21T21:45:39.243Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create new table to store lat and long information\n",
    "\n",
    "train_new['geom'] = train_new['LATITUDE'].map(str) + ',' + train_new['LONGITUDE'].map(str)\n",
    "train_new['geom'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-21T21:45:39.245Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install geopandas\n",
    "!pip install geopy\n",
    "import geopandas as gpd\n",
    "import geopy\n",
    "from geopy.geocoders import Nominatim\n",
    "from geopy.extra.rate_limiter import RateLimiter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-21T21:45:39.247Z"
    }
   },
   "outputs": [],
   "source": [
    "# timeout to prevent timeout errors\n",
    "locator = Nominatim(user_agent = 'myGeocoder', timeout=10)\n",
    "\n",
    "rgeocode = RateLimiter(locator.reverse, min_delay_seconds=0.0000000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-21T21:45:39.251Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install tqdm\n",
    "import tqdm\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "\n",
    "tqdm_notebook().pandas()\n",
    "\n",
    "#to much time consuming (7+ hours)\n",
    "#train_new['address'] = train_new['geom'].progress_apply(rgeocode)\n",
    "train_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-21T21:45:39.254Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import folium\n",
    "from folium.plugins import MarkerCluster\n",
    "\n",
    "map3 = folium.Map(location = [41.864073,-87.706819], zoom_start = 10.5)\n",
    "\n",
    "marker_cluster = folium.plugins.MarkerCluster().add_to(map3)\n",
    "\n",
    "locations = train_new[['LATITUDE', 'LONGITUDE']]\n",
    "locationlist = locations.values.tolist()\n",
    "\n",
    "for point in range(0, len(locationlist)):\n",
    "    folium.Marker(locationlist[point], icon = folium.Icon(color = 'darkblue', icon_color='white', icon='male', \n",
    "                                                          angle=0, prefix='fa')).add_to(marker_cluster)\n",
    "map3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**These 8 ommunities collectively account for 60% of fatal crashes!**\n",
    "\n",
    "- **South Deering:** 22% Fatality\n",
    "\n",
    "\n",
    "- **North Lawndale:** 7% Fatality\n",
    "\n",
    "\n",
    "- **West Elsdon:** 7% Fatality\n",
    "\n",
    "\n",
    "- **Pullman:** 7% Fatality\n",
    "\n",
    "\n",
    "- **West Englewood:** 7% Fatality\n",
    "\n",
    "\n",
    "- **Lake View:** 5% Fatality\n",
    "\n",
    "\n",
    "- **Garfield Ridge:** 5% Fatality\n",
    "\n",
    "\n",
    "- **Hegewisch:** 5% Fatality\n",
    "\n",
    "\n",
    "Collectively account for more than 60% fata crashes, but only 20% of Chicago’s area and 25% of the city’s population. (Fact check needed)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "288px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
